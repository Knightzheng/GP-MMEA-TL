[RUN] D:\Anaconda_envs\envs\bysj-meaformer\python.exe main.py --gpu 0 --eval_epoch 1 --only_test 0 --model_name MEAformer --data_choice DBP15K --data_split ja_en --data_rate 0.3 --epoch 3 --lr 0.0003 --hidden_units 64,64,64 --save_model 0 --batch_size 32 --csls_k 3 --random_seed 123 --exp_name BYSJ_MEAformer_rtx3060_safe_epoch3_multiseed --exp_id v1_ja_en_0.3_safe_epoch3_s123 --workers 1 --dist 0 --accumulation_steps 1 --scheduler cos --attr_dim 64 --img_dim 64 --name_dim 64 --char_dim 64 --hidden_size 64 --tau 0.1 --structure_encoder gat --num_attention_heads 1 --num_hidden_layers 1 --use_surface 0 --use_intermediate 1 --replay 0 --csls
The syntax of the command is incorrect.
INFO - 03/01/26 17:50:43 - 0:00:00 - ============ Initialized logger ============
INFO - 03/01/26 17:50:43 - 0:00:00 - The experiment will be stored in D:\code\codes\cursor\BYSJ_zyf\data\mmkg\dump/0301-BYSJ_MEAformer_rtx3060_safe_epoch3_multiseed\MEAformer_DBP15K_ja_en_v1_ja_en_0.3_safe_epoch3_s123

INFO - 03/01/26 17:50:43 - 0:00:00 - Running command: python main.py --gpu 0 --eval_epoch 1 --only_test 0 --model_name MEAformer --data_choice DBP15K --data_split ja_en --data_rate '0.3' --epoch 3 --lr '0.0003' --hidden_units '64,64,64' --save_model 0 --batch_size 32 --csls_k 3 --random_seed 123 --exp_name BYSJ_MEAformer_rtx3060_safe_epoch3_multiseed --exp_id 'v1_ja_en_0.3_safe_epoch3_s123' --workers 1 --dist 0 --accumulation_steps 1 --scheduler cos --attr_dim 64 --img_dim 64 --name_dim 64 --char_dim 64 --hidden_size 64 --tau '0.1' --structure_encoder gat --num_attention_heads 1 --num_hidden_layers 1 --use_surface 0 --use_intermediate 1 --replay 0 --csls

D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\main.py:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = GradScaler()
INFO - 03/01/26 17:50:46 - 0:00:03 - 66.88% entities have images
INFO - 03/01/26 17:50:46 - 0:00:03 - image feature shape:(39594, 2048)
INFO - 03/01/26 17:50:46 - 0:00:03 - #left entity : 19814, #right entity: 19780
INFO - 03/01/26 17:50:46 - 0:00:03 - #left entity not in train set: 15314, #right entity not in train set: 15280
INFO - 03/01/26 17:50:46 - 0:00:04 - relation feature shape:(39594, 1000)
INFO - 03/01/26 17:50:47 - 0:00:04 - attribute feature shape:(39594, 1000)
INFO - 03/01/26 17:50:47 - 0:00:04 - -----dataset summary-----
INFO - 03/01/26 17:50:47 - 0:00:04 - dataset:		 D:\code\codes\cursor\BYSJ_zyf\data\mmkg\DBP15K\ja_en
INFO - 03/01/26 17:50:47 - 0:00:04 - triple num:	 170698
INFO - 03/01/26 17:50:47 - 0:00:04 - entity num:	 39594
INFO - 03/01/26 17:50:47 - 0:00:04 - relation num:	 2452
INFO - 03/01/26 17:50:47 - 0:00:04 - train ill num:	 4500 	 test ill num:	 10500
INFO - 03/01/26 17:50:47 - 0:00:04 - -------------------------
D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\src\utils.py:237: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\utils\tensor_new.cpp:655.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO - 03/01/26 17:50:48 - 0:00:05 - Random init...
INFO - 03/01/26 17:50:48 - 0:00:05 - total params num: 2888342
INFO - 03/01/26 17:50:48 - 0:00:05 - warmup_steps: 63
INFO - 03/01/26 17:50:48 - 0:00:05 - total_steps: 423
INFO - 03/01/26 17:50:48 - 0:00:05 - weight_decay: 0.0001
loading raw data...
getting a sparse tensor r_adj...

  0%|          | 0/3 [00:00<?, ?it/s]
Train | Ep [0/3] Step [142/423] LR [0.00027] Loss 3315.51926 :   0%|          | 0/3 [13:03<?, ?it/s]INFO - 03/01/26 18:03:58 - 0:13:15 - Ep 0 | l2r: acc of top [1, 10, 50] = [0.5499 0.8525 0.962 ], mr = 10.711, mrr = 0.653, Loss = 3315.5193
INFO - 03/01/26 18:03:58 - 0:13:15 - Ep 0 | r2l: acc of top [1, 10, 50] = [0.5466 0.8564 0.9633], mr = 10.211, mrr = 0.651, Loss = 3315.5193
INFO - 03/01/26 18:03:58 - 0:13:15 - Best model update in Ep 0: MRR from [0.0] --> [0.6529446397055808] ...

Train | Ep [0/3] Step [142/423] LR [0.00027] Loss 3315.51926 :  33%|��������      | 1/3 [13:07<26:15, 787.95s/it]
Train | Ep [1/3] Step [283/423] LR [0.00010] Loss 1321.06234 :  33%|��������      | 1/3 [25:58<26:15, 787.95s/it]INFO - 03/01/26 18:16:54 - 0:26:11 - Ep 1 | l2r: acc of top [1, 10, 50] = [0.5995 0.8808 0.9746], mr = 7.866, mrr = 0.695, Loss = 1321.0623
INFO - 03/01/26 18:16:54 - 0:26:11 - Ep 1 | r2l: acc of top [1, 10, 50] = [0.5969 0.8825 0.9746], mr = 7.980, mrr = 0.694, Loss = 1321.0623
INFO - 03/01/26 18:16:54 - 0:26:11 - Best model update in Ep 1: MRR from [0.6529446397055808] --> [0.695019440889519] ...

Train | Ep [1/3] Step [283/423] LR [0.00010] Loss 1321.06234 :  67%|��������������   | 2/3 [26:04<13:00, 780.97s/it]
Train | Ep [2/3] Step [424/423] LR [0.00000] Loss 1024.63210 :  67%|��������������   | 2/3 [42:03<13:00, 780.97s/it]INFO - 03/01/26 18:33:00 - 0:42:17 - Ep 2 | l2r: acc of top [1, 10, 50] = [0.5865 0.87   0.9728], mr = 8.555, mrr = 0.682, Loss = 1024.6321
INFO - 03/01/26 18:33:00 - 0:42:17 - Ep 2 | r2l: acc of top [1, 10, 50] = [0.5842 0.8714 0.9719], mr = 8.658, mrr = 0.681, Loss = 1024.6321

Train | Ep [2/3] Step [424/423] LR [0.00000] Loss 1024.63210 : 100%|��������������������| 3/3 [42:09<00:00, 865.41s/it]
Train | Ep [2/3] Step [424/423] LR [0.00000] Loss 1024.63210 : 100%|��������������������| 3/3 [42:09<00:00, 843.31s/it]
INFO - 03/01/26 18:33:00 - 0:42:17 - load from the best model before final testing ...
INFO - 03/01/26 18:33:00 - 0:42:17 -  --------------------- Test result ---------------------
INFO - 03/01/26 18:33:07 - 0:42:25 - Ep 2 | l2r: acc of top [1, 10, 50] = [0.5995 0.8808 0.9746], mr = 7.866, mrr = 0.695, Loss = 1024.6321
INFO - 03/01/26 18:33:07 - 0:42:25 - Ep 2 | r2l: acc of top [1, 10, 50] = [0.5969 0.8825 0.9746], mr = 7.980, mrr = 0.694, Loss = 1024.6321
INFO - 03/01/26 18:33:07 - 0:42:25 - min loss 1024.6320962905884
INFO - 03/01/26 18:33:07 - 0:42:25 - done!
[DONE] return_code=0
