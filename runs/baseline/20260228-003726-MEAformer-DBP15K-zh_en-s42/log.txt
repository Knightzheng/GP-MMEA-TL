[RUN] D:\Anaconda_envs\envs\bysj-meaformer\python.exe main.py --gpu 0 --eval_epoch 1 --only_test 0 --model_name MEAformer --data_choice DBP15K --data_split zh_en --data_rate 0.3 --epoch 1 --lr 0.0005 --hidden_units 300,300,300 --save_model 0 --batch_size 3500 --csls_k 3 --random_seed 42 --exp_name BYSJ_MEAformer_bootstrap --exp_id v1_zh_en_0.3 --workers 4 --dist 0 --accumulation_steps 1 --scheduler cos --attr_dim 300 --img_dim 300 --name_dim 300 --char_dim 300 --hidden_size 300 --tau 0.1 --structure_encoder gat --num_attention_heads 1 --num_hidden_layers 1 --use_surface 0 --use_intermediate 1 --replay 0 --csls --enable_sota
INFO - 02/28/26 00:37:29 - 0:00:00 - ============ Initialized logger ============
INFO - 02/28/26 00:37:29 - 0:00:00 - The experiment will be stored in D:\code\codes\cursor\BYSJ_zyf\data\mmkg\dump/0228-BYSJ_MEAformer_bootstrap\MEAformer_DBP15K_zh_en_v1_zh_en_0.3

INFO - 02/28/26 00:37:29 - 0:00:00 - Running command: python main.py --gpu 0 --eval_epoch 1 --only_test 0 --model_name MEAformer --data_choice DBP15K --data_split zh_en --data_rate '0.3' --epoch 1 --lr '0.0005' --hidden_units '300,300,300' --save_model 0 --batch_size 3500 --csls_k 3 --random_seed 42 --exp_name BYSJ_MEAformer_bootstrap --exp_id 'v1_zh_en_0.3' --workers 4 --dist 0 --accumulation_steps 1 --scheduler cos --attr_dim 300 --img_dim 300 --name_dim 300 --char_dim 300 --hidden_size 300 --tau '0.1' --structure_encoder gat --num_attention_heads 1 --num_hidden_layers 1 --use_surface 0 --use_intermediate 1 --replay 0 --csls --enable_sota

D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\main.py:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = GradScaler()
INFO - 02/28/26 00:37:29 - 0:00:00 - 88.45% entities have images
INFO - 02/28/26 00:37:29 - 0:00:00 - image feature shape:(38960, 300)
INFO - 02/28/26 00:37:29 - 0:00:01 - #left entity : 19388, #right entity: 19572
INFO - 02/28/26 00:37:29 - 0:00:01 - #left entity not in train set: 14888, #right entity not in train set: 15072
INFO - 02/28/26 00:37:29 - 0:00:01 - relation feature shape:(38960, 1000)
INFO - 02/28/26 00:37:30 - 0:00:01 - attribute feature shape:(38960, 1000)
INFO - 02/28/26 00:37:30 - 0:00:01 - -----dataset summary-----
INFO - 02/28/26 00:37:30 - 0:00:01 - dataset:		 D:\code\codes\cursor\BYSJ_zyf\data\mmkg\DBP15K\zh_en
INFO - 02/28/26 00:37:30 - 0:00:01 - triple num:	 165556
INFO - 02/28/26 00:37:30 - 0:00:01 - entity num:	 38960
INFO - 02/28/26 00:37:30 - 0:00:01 - relation num:	 2133
INFO - 02/28/26 00:37:30 - 0:00:01 - train ill num:	 4500 	 test ill num:	 10500
INFO - 02/28/26 00:37:30 - 0:00:01 - -------------------------
D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\src\utils.py:237: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\utils\tensor_new.cpp:655.)
  return torch.sparse.FloatTensor(indices, values, shape)
INFO - 02/28/26 00:37:30 - 0:00:02 - Random init...
INFO - 02/28/26 00:37:30 - 0:00:02 - total params num: 13106206
INFO - 02/28/26 00:37:30 - 0:00:02 - warmup_steps: 75
INFO - 02/28/26 00:37:30 - 0:00:02 - total_steps: 500
INFO - 02/28/26 00:37:30 - 0:00:02 - weight_decay: 0.0001
loading raw data...
getting a sparse tensor r_adj...

  0%|          | 0/250 [00:00<?, ?it/s]
  0%|          | 0/250 [00:53<?, ?it/s]
Traceback (most recent call last):
  File "D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\main.py", line 536, in <module>
    runner.run()
  File "D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\main.py", line 222, in run
    self.train(_tqdm)
  File "D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\main.py", line 282, in train
    self.scaler.scale(loss).backward()
  File "D:\Anaconda_envs\envs\bysj-meaformer\lib\site-packages\torch\_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "D:\Anaconda_envs\envs\bysj-meaformer\lib\site-packages\torch\autograd\__init__.py", line 354, in backward
    _engine_run_backward(
  File "D:\Anaconda_envs\envs\bysj-meaformer\lib\site-packages\torch\autograd\graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "D:\Anaconda_envs\envs\bysj-meaformer\lib\site-packages\torch\autograd\function.py", line 311, in apply
    return user_fn(self, *args)
  File "D:\code\codes\cursor\BYSJ_zyf\baselines\MEAformer\model\layers.py", line 26, in backward
    grad_a_dense = grad_output.matmul(b.t())
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.66 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 3.87 GiB is allocated by PyTorch, and 5.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[DONE] return_code=1
